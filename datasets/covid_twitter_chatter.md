---
api_or_bulk_downloads: Bulk
citation: "\n@misc{banda_large-scale_2021,\n        title = {A large-scale {COVID}-19
  {Twitter} chatter dataset for open scientific research - an international collaboration},\n
  \       url = {https://zenodo.org/record/5458943},\n        abstract = {Version
  78 of the dataset. The peer-reviewed publication for this dataset has now been published 
  in Epidemiologia an MDPI journal, and can be accessed here: https://doi.org/10.3390/epidemiologia2030024.
  Please cite this when using the dataset. Due to the relevance of the COVID-19 global
  pandemic, we are releasing our dataset of tweets acquired from the Twitter Stream
  related to COVID-19 chatter. Since our first release we have received additional
  data from our new collaborators, allowing this resource to grow to its current size.
  Dedicated data gathering started from March 11th yielding over 4 million tweets
  a day. We have added additional data provided by our new collaborators from January
  27th to March 27th, to provide extra longitudinal coverage. Version 10 added {\\textasciitilde}1.5
  million tweets in the Russian language collected between January 1st and May 8th,
  gracefully provided to us by: Katya Artemova (NRU HSE) and Elena Tutubalina (KFU).
  From version 12 we have included daily hashtags, mentions and emoijis and their
  frequencies the respective zip files. From version 14 we have included the tweet
  identifiers and their respective language for the clean version of the dataset.
  Since version 20 we have included language and place location for all tweets. The
  data collected from the stream captures all languages, but the higher prevalence
  are:  English, Spanish, and French. We release all tweets and retweets on the full\\_dataset.tsv
  file (1,198,902,806 unique tweets), and a cleaned version with no retweets on the
  full\\_dataset-clean.tsv file (306,791,449 unique tweets). There are several practical
  reasons for us to leave the retweets, tracing important tweets and their dissemination
  is one of them. For NLP tasks we provide the top 1000 frequent terms in frequent\\_terms.csv,
  the top 1000 bigrams in frequent\\_bigrams.csv, and the top 1000 trigrams in frequent\\_trigrams.csv.
  Some general statistics per day are included for both datasets in the full\\_dataset-statistics.tsv
  and full\\_dataset-clean-statistics.tsv files. For more statistics and some visualizations
  visit: http://www.panacealab.org/covid19/  More details can be found (and will be
  updated faster at: https://github.com/thepanacealab/covid19\\_twitter) and our pre-print
  about the dataset (https://arxiv.org/abs/2004.03688)  As always, the tweets distributed
  here are only tweet identifiers (with date and time added) due to the terms and
  conditions of Twitter to re-distribute Twitter data ONLY for research purposes.
  They need to be hydrated to be used.},\n        urldate = {2021-09-07},\n        publisher
  = {Zenodo},\n        author = {Banda, Juan M. and Tekumalla, Ramya and Wang, Guanyu
  and Yu, Jingyuan and Liu, Tuo and Ding, Yuning and Artemova, Katya and Tutubalina,
  Elena and Chowell, Gerardo},\n        month = sep,\n        year = {2021},\n        doi
  = {10.5281/zenodo.5458943},\n        note = {type: dataset},\n        keywords =
  {social media, twitter, nlp, covid-19, covid19},\n}\n"
code: https://github.com/thepanacealab/covid19_twitter
description: 'Dataset of tweets acquired from the Twitter Stream related to COVID-19
  chatter. The first 9 weeks of data (from January 1st, 2020 to March 11th, 2020)
  contain very low tweet counts as we filtered other data we were collecting for other
  research purposes, however, one can see the dramatic increase as the awareness for
  the virus spread. Dedicated data gathering started from March 11th yielding over
  4 million tweets a day.


  The data collected from the stream captures all languages, but the higher prevalence
  are: English, Spanish, and French. We release all tweets and retweets on the full
  dataset, and a cleaned version with no retweets. There are several practical reasons
  for us to leave the retweets, tracing important tweets and their dissemination is
  one of them. For NLP tasks we provide the top 1000 frequent terms, the top 1000
  bigrams, and the top 1000 trigrams. Some general statistics per day are included
  for both datasets.'
documentation: http://www.panacealab.org/covid19/
doi: 'DOI: 10.5281/zenodo.5458943

  type: dataset'
error_metrics: null
record_creation_timestamp: 09/07/2021, 16:35:04
references: null
shortname: covid_twitter_chatter
tags: social media, twitter, nlp, covid-19, covid19, twitter, covid, open-source
terms_of_use: null
timeframe: Jan 2020-present
title: A large-scale COVID-19 Twitter chatter dataset for open scientific research
location: https://zenodo.org/record/5458943
uuid: 1a7fc85d-38af-4fe6-83b8-0d629e85d418
versioning: 'Yes'
---